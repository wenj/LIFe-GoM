<!DOCTYPE html>
<html>

<head lang="en">
  <!-- <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> -->

  <!-- <meta http-equiv="x-ua-compatible" content="ie=edge"> -->

  <title>LIFe-GoM</title>

  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- mirror: F0%9F%AA%9E&lt -->

  <link rel="stylesheet" type="text/css" href="./files/slick.css">
  <link rel="stylesheet" type="text/css" href="./files/slick-theme.css">
  <link rel="stylesheet" href="./files/bulma.min.css">
  <link rel="stylesheet" href="./files/bulma-slider.min.css">
  <link rel="stylesheet" href="./files/bulma-carousel.min.css">
  <link rel="stylesheet" href="./files/bootstrap.min.css">
  <link rel="stylesheet" href="./files/font-awesome.min.css">
  <link rel="stylesheet" href="./files/codemirror.min.css">
  <link rel="stylesheet" href="./files/app.css">
  <link rel="stylesheet" href="./files/index.css">
  <link rel="stylesheet" href="./files/select.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="resources/glide.core.min.css">
  <link rel="stylesheet" href="resources/glide.theme.min.css">
  <link rel="stylesheet" href="resources/glide-custom.css">
  <script src="resources/handlers.js"></script>
  <script src="./files/jquery.min.js"></script>
  <script src="./files/bootstrap.min.js"></script>
  <script src="./files/codemirror.min.js"></script>
  <script src="./files/clipboard.min.js"></script>
  <script src="./files/video_comparison.js"></script>
  <script src="./files/select.js"></script>
  <script src="./files/bulma-slider.min.js"></script>
  <script src="./files/bulma-carousel.min.js"></script>
  <!-- <script src="./files/app.js"></script> -->
  <script src="./files/index.js"></script>
  <!-- <script src="./files/slick.js"></script> -->

  <script src="resources/glide.min.js"></script>
  <script>
    window.onload = function () {
      new Glide("#dynamic-carousel", {
        type: "carousel",
        perView: 1.68,
        focusAt: "center",
        autoplay: 20000,
        hoverpause: true
      }).mount();
      new Glide("#static-carousel", {
        type: "carousel",
        perView: 1.68,
        focusAt: "center",
        autoplay: 3000,
        hoverpause: true
      }).mount();
      new Glide("#realtime-carousel", {
        type: "carousel",
        perView: 2.05,
        focusAt: "center",
        autoplay: 3000,
        hoverpause: true
      }).mount();
    };
  </script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RZ6PES7EKD"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-RZ6PES7EKD');
  </script>
</head>

<body>
  <div class="container" id="header" style="text-align: center; margin: auto;">
    <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
      <h2 class="col-md-12 text-center" id="title">
        LIFe-GoM: Generalizable Human Rendering with Learned Iterative Feedback Over Multi-Resolution Gaussians-on-Mesh
      </h2>
      <h3 class="col-md-12 text-center" id="title">
        ICLR 2025
      </h3>
    </div>
  </div>
  <script>
  </script>
  <div class="container" id="main">
    <div class="row">
      <div class="col-sm-10 col-sm-offset-1 text-center">
        <ul class="list-inline">
          <li> <a href="https://wenj.github.io/">Jing Wen</a> </li>
          <li> <a href="https://www.alexander-schwing.de/">Alexander G. Schwing</a> </li>
          <li> <a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a> </li>
        </ul>
        <ul class="list-inline">
          <li> University of Illinois at Urbana-Champaign </li>
          <br />
        </ul>
      </div>
    </div>

    <div class="row">
      <div class="col-sm-8 col-sm-offset-2 text-center">
        <span class="link-block">
          <a href="https://arxiv.org/abs/2404.07991" class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas"
                data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"
                data-fa-i2svg="">
                <path fill="currentColor"
                  d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z">
                </path>
              </svg>
            </span>
            <span>Paper</span>
          </a>
        </span>
        <span class="link-block">
          <a href="https://github.com/wenj/GoMAvatar"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab"
                data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg="">
                <path fill="currentColor"
                  d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
                </path>
              </svg>
            </span>
            <span>Code</span>
          </a>
        </span>
      </div>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Abstract
        </h3>
        <div class="text-justify">
          Generalizable rendering of an animatable human avatar from sparse inputs relies on data priors and inductive biases extracted from training on large data to avoid scene-specific optimization and to enable fast reconstruction. This raises two main challenges: First, unlike iterative gradient-based adjustment in scene-specific optimization, generalizable methods must reconstruct the human shape representation in a single pass at inference time. Second, rendering is preferably computationally efficient yet of high resolution. To address both challenges we augment the recently proposed dual shape representation, which combines the benefits of a mesh and Gaussian points, in two ways. To improve reconstruction, we propose an iterative feedback update framework, which successively improves the canonical human shape representation during reconstruction. To achieve computationally efficient yet high-resolution rendering, we study a coupled-multi-resolution Gaussians-on-Mesh representation. We evaluate the proposed approach on the challenging THuman2.0, XHuman and AIST++ data. Our approach reconstructs an animatable  representation from sparse inputs in less than 1s, renders views with 95.1FPS at 1024x1024, and achieves  PSNR/LPIPS*/FID of 24.65/110.82/51.27 on THuman2.0, outperforming the state-of-the-art in rendering quality.
        </div>
        <br>
        <center>
          <img src="./medias/figures/teaser.png" class="img-responsive" alt="overview" width="100%"
            style="max-height: 500px;margin:auto;">
        </center>
      </div>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Novel view synthesis
        </h3>
        <div class="text-justify">
            In the following we present 360° freeview rendering and the comparison to GHG [1].
            <br>
            [1] Kwon, Youngjoong, et al. "Generalizable human gaussians for sparse view synthesis." ECCV 2024.
        </div>
        <br>

        <center>
          <ul class="nav nav-pills nav-justified" id="freeview" style="width: 100%">
            <li role="presentation" class="active"><a href="javascript: void(0);"
                onclick="ChangeSceneFreeview(0);">0006</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneFreeview(1);">0090</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneFreeview(2);">0270</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneFreeview(3);">0426</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneFreeview(4);">0474</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneFreeview(5);">0522</a>
            </li>
          </ul>
          <br>

          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="freeview_gt">
                  <source src="./medias/freeview/gt_0006.mp4" type="video/mp4"><br>
                </video>
                <h5>Ground truth</h5>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="freeview_ghg">
                  <source src="./medias/freeview/ghg_0006.mp4" type="video/mp4"><br>
                </video>
                <h5>GHG</h5>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="freeview_ours">
                  <source src="./medias/freeview/ours_0006.mp4" type="video/mp4"><br>
                </video>
                <h5>Ours</h5>
              </div>
            </div>
          </div>
        </center>
      </div>
    </div>
    <br>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Cross-domain generalization
        </h3>
        <div class="text-justify">
            In the following we show our method in cross-domain generalization. Our model is trained on THuman2.0. We apply to subjects in other datasets without finetuning.
        </div>
        <br>

        <h4>
          XHuman
        </h4>
        <div class="text-justify">
          The XHuman dataset provides 3D scans and corresponding SMPL-X poses. We render source images and input subject masks from the 3D scans and use the poses provided by the dataset as inputs.
          <br>
          In the first two examples, we take as inputs multiview images. In the last two examples, we take source images sampled from different frames, where the poses are different.
        </div>
        <br>

        <center>
          <ul class="nav nav-pills nav-justified" id="crossdomain_xhuman" style="width: 100%">
            <li role="presentation" class="active"><a href="javascript: void(0);"
                onclick="ChangeSceneCrossDomainXHuman(0);">00016 - multiview</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneCrossDomainXHuman(1);">00041 - multiview</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneCrossDomainXHuman(2);">00025 - multi-frame</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneCrossDomainXHuman(3);">00028 - multi-frame</a>
            </li>
          </ul>
          <br>

          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-8 col-md-8 col-xs-8 col-sm-8 pull-left" style="text-align: center;">
                <div><img src="./medias/crossdomain/scene_00016_Take1_f00001_frame_000000_input.png" class="img" width="100%" id="crossdomain_xhuman_ref"></div>
                <h5>Source images</h5>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="crossdomain_xhuman_video">
                  <source src="./medias/crossdomain/scene_00016_Take1_f00001_frame_000000.mp4" type="video/mp4"><br>
                </video>
                <h5>Ground truth</h5>
              </div>
            </div>
          </div>
        </center>

        <h4>
          PeopleSnapshot
        </h4>
        <div class="text-justify">
          The PeopleSnapshot provides monocular videos. We sample frames from the videos as source images. We follow ExAvatar to predict the SMPL-X poses and subject masks from the videos. Note that the input poses are not necessarily aligned.
        </div>
        <br>

        <center>
          <ul class="nav nav-pills nav-justified" id="crossdomain_pn" style="width: 100%">
            <li role="presentation" class="active"><a href="javascript: void(0);"
                onclick="ChangeSceneCrossDomainPN(0);">female-3-casual</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneCrossDomainPN(1);">male-3-casual</a>
            </li>
          </ul>
          <br>

          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-8 col-md-8 col-xs-8 col-sm-8 pull-left" style="text-align: center;">
                <div><img src="./medias/crossdomain/scene_f3c_input.png" class="img" width="100%" id="crossdomain_pn_ref"></div>
                <h5>Source images</h5>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="crossdomain_pn_video">
                  <source src="./medias/crossdomain/scene_f3c.mp4" type="video/mp4"><br>
                </video>
                <h5>Ground truth</h5>
              </div>
            </div>
          </div>
        </center>

        <h4>
          DNA-Rendering
        </h4>
        <div class="text-justify">
          The DNA-Rendering dataset provides multiview videos and corresponding SMPL-X poses. We sample multiview images from the dataset. We directly use the provided subject masks and SMPL-X poses as inputs. Note that the provided SMPL-X poses are not accurate enough, especially faces.
        </div>
        <br>

        <center>
          <ul class="nav nav-pills nav-justified" id="crossdomain_dna" style="width: 100%">
            <li role="presentation" class="active"><a href="javascript: void(0);"
                onclick="ChangeSceneCrossDomainDNA(0);">0008_01</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneCrossDomainDNA(1);">0152_01</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneCrossDomainDNA(2);">0310_04</a>
            </li>
          </ul>
          <br>

          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-8 col-md-8 col-xs-8 col-sm-8 pull-left" style="text-align: center;">
                <div><img src="./medias/crossdomain/scene_0008_01_000000_input.png" class="img" width="100%" id="crossdomain_dna_ref"></div>
                <h5>Source images</h5>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="crossdomain_dna_video">
                  <source src="./medias/crossdomain/scene_0008_01_000000_frame_000020.mp4" type="video/mp4"><br>
                </video>
                <h5>Ground truth</h5>
              </div>
            </div>
          </div>
        </center>
      </div>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Novel pose synthesis
        </h3>
        <div class="text-justify">
            In the following we present novel pose synthesis. We retarget the subject to new pose sequences from the BEDLAM dataset.
        </div>
        <br>

        <center>
          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <div><img src="./medias/novelpose/scene_0009.png" class="img" width="100%"></div>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <div><img src="./medias/novelpose/scene_0126.png" class="img" width="100%"></div>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <div><img src="./medias/novelpose/scene_0510.png" class="img" width="100%"></div>
              </div>
            </div>
            <h5 style="text-align:center; margin-top: 0pt; margin-bottom: 0pt;">Reference images</h5>
            <br>

            <div class="row">
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="nvs_rgb_hn">
                  <source src="./medias/novelpose/scene_0009_name_rp_eve_posed_001.mp4" type="video/mp4"><br>
                </video>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="nvs_rgb_mh">
                  <source src="./medias/novelpose/scene_0126_name_rp_eve_posed_001.mp4" type="video/mp4"><br>
                </video>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="nvs_rgb_ours">
                    <source src="./medias/novelpose/scene_0510_name_rp_eve_posed_001.mp4" type="video/mp4"><br>
                </video>
              </div>
            </div>
            <h5 style="text-align:center; margin-top: 0pt; margin-bottom: 0pt;">Novel pose synthesis</h5>
          </div>
        </center>

        <h4>Cross-domain examples</h4>
        <center>
          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted>
                  <source src="./medias/novelpose/scene_f3c_name_female_25_nl_2229.mp4" type="video/mp4"><br>
                </video>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted>
                  <source src="./medias/novelpose/scene_m3c_name_male_32_us_1533.mp4" type="video/mp4"><br>
                </video>
              </div>
            </div>
          </div>
        </center>
      </div>
    </div>
    <br>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Citation
        </h3>
        If you find our project useful, please consider citing:
        <br>

        <div class="CodeMirror cm-s-default CodeMirror-wrap">
          <div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 38.28px; left: 647px;">
            <textarea autocorrect="off" autocapitalize="off" spellcheck="false" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;" tabindex="0"></textarea>
          </div>
          <div class="CodeMirror-vscrollbar" cm-not-content="true">
            <div style="min-width: 1px; height: 0px;"></div>
          </div>
          <div class="CodeMirror-hscrollbar" cm-not-content="true">
            <div style="height: 100%; min-height: 1px; width: 0px;"></div>
          </div>
          <div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div>
          <div class="CodeMirror-gutter-filler" cm-not-content="true"></div>
          <div class="CodeMirror-scroll" tabindex="-1">
            <div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 111px; padding-right: 0px; padding-bottom: 0px;">
              <div style="position: relative; top: 0px;">
                <div class="CodeMirror-lines">
                  <div style="position: relative; outline: none;">
                    <div class="CodeMirror-measure">AخA</div>
                    <div class="CodeMirror-measure"></div>
                    <div style="position: relative; z-index: 1;"></div>
                    <div class="CodeMirror-cursors">
                      <div class="CodeMirror-cursor" style="left: 647px; top: 34.28px; height: 17.1406px;">&nbsp;</div>
                    </div>
                    <div class="CodeMirror-code" style="">
                      <pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">@inproceedings{wen2025lifegom,</span></pre>
                      <pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  title={{LIFe-GoM: Generalizable Human Rendering with Learned Iterative Feedback Over Multi-Resolution Gaussians-on-Mesh}},</span></pre>
                      <pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  author={Jing Wen and Alex Schwing and Shenlong Wang},</span></pre>
                      <pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  booktitle={ICLR},</span></pre>
                      <pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  year={2025}</span></pre>
                      <pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">}</span></pre>
                    </div>
                  </div>
                </div>
              </div>
            </div>
            <div style="position: absolute; height: 15px; width: 1px; top: 111px;"></div>
            <div class="CodeMirror-gutters" style="display: none; height: 126px;"></div>
          </div>
        </div>

      </div>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Acknowledgements
        </h3>

        The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and <A
          href="https://climatenerf.github.io/">ClimateNeRF</a>.

      </div>
    </div>
  </div>
</body>
f

</html>
